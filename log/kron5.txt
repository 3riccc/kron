nohup: ignoring input
{'node_num': 128, 'miss_percent': 0.1, 'seed': 2050, 'batch_size': 1024, 'lr_net': 0.001, 'lr_dyn': 0.0001}

Matrix dimension: torch.Size([128, 128]) 
Train data size: torch.Size([10000, 128, 2, 1]) 
Val data size: torch.Size([2000, 128, 2, 1]) 
Test data size: torch.Size([2000, 128, 2, 1])
epoch: 0
train loss: 0.010838473265878213
auc: 0.4980656013456686
epoch: 1
train loss: 0.005467824111863216
auc: 0.49903880812207135
epoch: 2
train loss: 0.003924175606541745
auc: 0.4981256758380392
epoch: 3
train loss: 0.0023762614460604804
auc: 0.5003484320557491
epoch: 4
train loss: 0.001427743199816052
auc: 0.500660819416076
epoch: 5
train loss: 0.0008533177575812041
auc: 0.5013576835275743
epoch: 6
train loss: 0.00036680834494071514
auc: 0.5010693259641956
epoch: 7
train loss: 0.00017953339033581494
auc: 0.5013817133245224
epoch: 8
train loss: 8.410348387017088e-05
auc: 0.5016941006848492
epoch: 9
train loss: 6.278410884737366e-05
auc: 0.5018623092634867
epoch: 10
train loss: 4.897702241076582e-05
auc: 0.5030037246185269
epoch: 11
train loss: 4.200407831674589e-05
auc: 0.5047458848972726
epoch: 12
train loss: 3.662113416253462e-05
auc: 0.5070767752012495
epoch: 13
train loss: 3.127027633691514e-05
auc: 0.5106211702511114
epoch: 14
train loss: 2.9885583008872972e-05
auc: 0.5165325003003725
epoch: 15
train loss: 2.8993137175348237e-05
auc: 0.5239577075573711
epoch: 16
train loss: 2.619516218060355e-05
auc: 0.5346269374023789
epoch: 17
train loss: 2.484695637890425e-05
auc: 0.5444791541511474
epoch: 18
train loss: 2.696652034595398e-05
auc: 0.5556409948335936
epoch: 19
train loss: 2.190073270557589e-05
auc: 0.5638231406944612
epoch: 20
train loss: 2.4036157881725778e-05
auc: 0.5727021506668268
epoch: 21
train loss: 2.4331304046325322e-05
auc: 0.5811486242941246
epoch: 22
train loss: 2.3198636381493997e-05
auc: 0.5865673435059474
epoch: 23
train loss: 2.940052661631006e-05
auc: 0.5936801634026193
epoch: 24
train loss: 2.803690018414931e-05
auc: 0.5972365733509551
epoch: 25
train loss: 2.6233052862043506e-05
auc: 0.6005406704313347
epoch: 26
train loss: 3.0244226415977117e-05
auc: 0.603340141775802
epoch: 27
train loss: 4.111399202276422e-05
auc: 0.6020185029436501
epoch: 28
train loss: 3.8060534376623326e-05
auc: 0.604349393247627
epoch: 29
train loss: 3.305591003168204e-05
auc: 0.6074612519524211
epoch: 30
train loss: 3.912276771710163e-05
auc: 0.607353117866154
epoch: 31
train loss: 3.958730400866224e-05
auc: 0.6098281869518203
epoch: 32
train loss: 3.859639903131712e-05
auc: 0.6131202691337259
epoch: 33
train loss: 3.5326209630793844e-05
auc: 0.6133004926108374
epoch: 34
train loss: 3.4440658944355355e-05
auc: 0.6138772077375947
epoch: 35
train loss: 3.240236165640517e-05
auc: 0.6147062357323081
epoch: 36
train loss: 2.9744113094003643e-05
auc: 0.615138772077376
epoch: 37
train loss: 3.0170737920994286e-05
auc: 0.6145620569506187
epoch: 38
train loss: 2.6046254240280427e-05
auc: 0.615258921062117
epoch: 39
train loss: 2.536091033264178e-05
auc: 0.6159557851736153
epoch: 40
train loss: 2.8341759467554673e-05
auc: 0.6174456325844047
epoch: 41
train loss: 2.291290995819101e-05
auc: 0.619151748167728
epoch: 42
train loss: 2.3004746235881548e-05
auc: 0.6211462213144299
epoch: 43
train loss: 2.088904527093699e-05
auc: 0.6234530818214586
epoch: 44
train loss: 2.4908905652213874e-05
auc: 0.6243421843085426
epoch: 45
train loss: 2.466404417285456e-05
auc: 0.6283431455004205
epoch: 46
train loss: 2.5901823328201224e-05
auc: 0.6319956746365494
epoch: 47
train loss: 2.6082520255464447e-05
auc: 0.6335936561336057
epoch: 48
train loss: 2.772599893240834e-05
auc: 0.6364532019704434
epoch: 49
train loss: 2.9037284899255483e-05
auc: 0.6360687252192718
epoch: 50
train loss: 2.9149345490670132e-05
auc: 0.6359125315391085
epoch: 51
train loss: 2.7564149233732115e-05
auc: 0.6360326805238496
epoch: 52
train loss: 2.9060808039056266e-05
auc: 0.6334975369458128
epoch: 53
train loss: 2.690915478128459e-05
auc: 0.633521566742761
epoch: 54
train loss: 2.390704334947384e-05
auc: 0.6334975369458128
epoch: 55
train loss: 3.129759874970408e-05
auc: 0.6295085906524089
epoch: 56
train loss: 3.4180083899423936e-05
auc: 0.6274660579118108
epoch: 57
train loss: 3.8253063663738616e-05
auc: 0.6259762105010214
epoch: 58
train loss: 3.4006592706787316e-05
auc: 0.6263486723537186
epoch: 59
train loss: 3.3751367636835406e-05
auc: 0.6255797188513756
epoch: 60
train loss: 3.1914986968315824e-05
auc: 0.6250750931154632
epoch: 61
train loss: 3.498369070837662e-05
auc: 0.6247146461612398
epoch: 62
train loss: 3.604389043065849e-05
auc: 0.6232968881412952
epoch: 63
train loss: 3.921528405279442e-05
auc: 0.6209179382434218
epoch: 64
train loss: 4.106380838199333e-05
auc: 0.6191757779646762
epoch: 65
train loss: 3.805230481910665e-05
auc: 0.618935479995194
epoch: 66
train loss: 3.3810990385259646e-05
auc: 0.6182866754775922
epoch: 67
train loss: 3.322644357812633e-05
auc: 0.6170371260362849
epoch: 68
train loss: 3.27419847571005e-05
auc: 0.6188393608074012
epoch: 69
train loss: 3.147261601427466e-05
auc: 0.6191157034723056
epoch: 70
train loss: 2.868368269563971e-05
auc: 0.6188033161119788
epoch: 71
train loss: 2.942610968947802e-05
auc: 0.6201009251471825
epoch: 72
train loss: 3.3175664195980435e-05
auc: 0.620593535984621
epoch: 73
train loss: 3.6164201168472134e-05
auc: 0.6214225639793344
epoch: 74
train loss: 3.459236468306072e-05
auc: 0.6216148023549202
epoch: 75
train loss: 3.031399818970887e-05
auc: 0.6190676438784093
epoch: 76
train loss: 3.633104686875005e-05
auc: 0.6171092154271297
epoch: 77
train loss: 3.296270823354995e-05
auc: 0.6137931034482759
epoch: 78
train loss: 2.9870271169266776e-05
auc: 0.6117385558092034
epoch: 79
train loss: 2.8841046808589327e-05
auc: 0.6079899074852818
epoch: 80
train loss: 2.9183199883234545e-05
auc: 0.6051664063438664
epoch: 81
train loss: 2.6776768976529198e-05
auc: 0.602330890303977
epoch: 82
train loss: 2.4886620279034857e-05
auc: 0.6006007449237054
epoch: 83
train loss: 2.3899917554531228e-05
auc: 0.5993992550762947
epoch: 84
train loss: 2.1123824392126498e-05
auc: 0.5983900036044696
epoch: 85
train loss: 2.2818260121986333e-05
auc: 0.5957226961432176
epoch: 86
train loss: 2.6939590804102347e-05
auc: 0.5948095638591854
epoch: 87
train loss: 3.618068742839412e-05
auc: 0.596107172894389
epoch: 88
train loss: 2.719805329865392e-05
auc: 0.5970443349753695
epoch: 89
train loss: 2.4824141471840293e-05
auc: 0.5988585846449597
epoch: 90
train loss: 2.4030071097450703e-05
auc: 0.6010933557611438
epoch: 91
train loss: 2.4711833842455486e-05
auc: 0.6039529015979814
epoch: 92
train loss: 2.0277527078335346e-05
auc: 0.6062717770034843
epoch: 93
train loss: 2.1253182022315614e-05
auc: 0.6089631142616845
epoch: 94
train loss: 1.9663438146427984e-05
auc: 0.6123753454283312
epoch: 95
train loss: 1.8619163983524638e-05
auc: 0.6151267571789019
epoch: 96
train loss: 1.7528649484653402e-05
auc: 0.6185029436501261
epoch: 97
train loss: 1.643868705847471e-05
auc: 0.6217950258320317
epoch: 98
train loss: 1.5233121493550024e-05
auc: 0.6252072569986783
epoch: 99
train loss: 1.3774586257544923e-05
auc: 0.6294845608554608
