nohup: ignoring input

Matrix dimension: torch.Size([128, 128]) 
Train data size: torch.Size([2500, 128, 2, 1]) 
Val data size: torch.Size([500, 128, 2, 1]) 
Test data size: torch.Size([500, 128, 2, 1])
epoch: 0
train loss: 0.03208387052893221
auc: 0.500446703403955
epoch: 1
train loss: 0.005588593930554651
auc: 0.49957957326686586
epoch: 2
train loss: 0.001556898172650066
auc: 0.49862985930719683
epoch: 3
train loss: 0.0004916033768317536
auc: 0.49866739740836946
epoch: 4
train loss: 0.0002826064540375688
auc: 0.4986486283577831
epoch: 5
train loss: 0.00023745091663119542
auc: 0.49862610549707953
epoch: 6
train loss: 0.0002088983782592006
auc: 0.4988625955344675
epoch: 7
train loss: 0.00014823847017731
auc: 0.49906154747068265
epoch: 8
train loss: 0.000154676426231079
auc: 0.4990315169897445
epoch: 9
train loss: 0.00015050392225041822
auc: 0.49932431417889156
epoch: 10
train loss: 0.00018216825683130188
auc: 0.49939939038123693
epoch: 11
train loss: 0.0003628856982205675
auc: 0.5004279343533686
epoch: 12
train loss: 0.00025525090165303126
auc: 0.501088604934008
epoch: 13
train loss: 0.00013416270694401698
auc: 0.5011636811363533
epoch: 14
train loss: 0.0001695464133336336
auc: 0.5014076787939759
epoch: 15
train loss: 0.00012569543938381644
auc: 0.5022109941590716
epoch: 16
train loss: 0.0001951395741594626
auc: 0.5030968933467469
epoch: 17
train loss: 0.00010604292245930657
auc: 0.5033258757639003
epoch: 18
train loss: 0.00012459367234305842
auc: 0.5028754185498281
epoch: 19
train loss: 0.0001890159610254692
auc: 0.504226790192045
epoch: 20
train loss: 9.700505720554676e-05
auc: 0.5045683869127163
epoch: 21
train loss: 0.00015238087712793783
auc: 0.5051051817594858
epoch: 22
train loss: 0.0001066520583809433
auc: 0.5044520187990811
epoch: 23
train loss: 0.00011838016914863282
auc: 0.5048611841018633
epoch: 24
train loss: 9.158804844435968e-05
auc: 0.5063814771993573
epoch: 25
train loss: 0.00013400789045078256
auc: 0.5065316296040481
epoch: 26
train loss: 0.00014514136862727492
auc: 0.506054895719155
epoch: 27
train loss: 8.618117606173414e-05
auc: 0.5065053529332273
epoch: 28
train loss: 0.00013912445155224776
auc: 0.5083221970299854
epoch: 29
train loss: 9.766350958880035e-05
auc: 0.5082809051186955
epoch: 30
train loss: 0.0002864697937560589
auc: 0.5083559813210409
epoch: 31
train loss: 0.00019688817547862056
auc: 0.5075639273862971
epoch: 32
train loss: 0.00014448272649415545
auc: 0.5069032568056577
epoch: 33
train loss: 0.00014288940360790873
auc: 0.5051089355696032
epoch: 34
train loss: 0.00011782567213523942
auc: 0.5023761618042313
epoch: 35
train loss: 0.00010886534644292812
auc: 0.49959083469721766
epoch: 36
train loss: 8.382736884685847e-05
auc: 0.49789035871409476
epoch: 37
train loss: 8.62564064866991e-05
auc: 0.49748494722142966
epoch: 38
train loss: 8.990044769798887e-05
auc: 0.49729350290544905
epoch: 39
train loss: 0.00012667651800131414
auc: 0.49393008904037594
epoch: 40
train loss: 0.0001833063290972462
auc: 0.48828060481388613
epoch: 41
train loss: 0.00026469336023507206
auc: 0.48804786858661536
epoch: 42
train loss: 0.00017749133142377566
auc: 0.49004489556900255
epoch: 43
train loss: 9.874848766052853e-05
auc: 0.4919030315770507
epoch: 44
train loss: 8.884703835200912e-05
auc: 0.4929616060301206
epoch: 45
train loss: 9.304611677995629e-05
auc: 0.49159897295755195
epoch: 46
train loss: 0.00015247089501419146
auc: 0.49188426252646433
epoch: 47
train loss: 0.0001643646405734645
auc: 0.49391507379990696
epoch: 48
train loss: 0.00020139193847349272
auc: 0.4955367197705671
epoch: 49
train loss: 0.00020336709198529897
auc: 0.4927101007522635
epoch: 50
train loss: 0.00019140538733018343
auc: 0.49175287917236
epoch: 51
train loss: 0.0001433015695092972
auc: 0.4907431042508146
epoch: 52
train loss: 9.255786096020173e-05
auc: 0.48934668688719046
epoch: 53
train loss: 0.00011565156474957228
auc: 0.4883406657757624
epoch: 54
train loss: 0.0001367575286815412
auc: 0.48760491899277764
epoch: 55
train loss: 0.000166033610456771
auc: 0.48641496118560335
epoch: 56
train loss: 0.00020254031845582375
auc: 0.4837084640910524
epoch: 57
train loss: 0.00012179392437790467
auc: 0.48208681812039217
epoch: 58
train loss: 0.00011065962369935608
auc: 0.4798533011006171
epoch: 59
train loss: 9.006807045159218e-05
auc: 0.47834426943347497
epoch: 60
train loss: 0.0001159929115026731
auc: 0.47646361056472314
epoch: 61
train loss: 0.0001413408179401792
auc: 0.47629844291956325
epoch: 62
train loss: 0.0001397448858808965
auc: 0.47505968558086453
epoch: 63
train loss: 0.00013272992120995508
auc: 0.4741888016336581
epoch: 64
train loss: 8.821476020439777e-05
auc: 0.4732916410156308
epoch: 65
train loss: 8.729778948231118e-05
auc: 0.4734830853316116
epoch: 66
train loss: 7.442141020811536e-05
auc: 0.4742300935449481
epoch: 67
train loss: 7.160643942380825e-05
auc: 0.47414000210213364
epoch: 68
train loss: 7.497361970120531e-05
auc: 0.47550638898481956
epoch: 69
train loss: 6.50828700908351e-05
auc: 0.4750897160618027
epoch: 70
train loss: 6.221922912714192e-05
auc: 0.4744628297722188
epoch: 71
train loss: 5.7438910035911585e-05
auc: 0.47551389660505416
epoch: 72
train loss: 4.161239427236884e-05
auc: 0.4759118004774846
epoch: 73
train loss: 3.733178429642087e-05
auc: 0.4760244147810027
epoch: 74
train loss: 3.972881898951674e-05
auc: 0.4763997957927296
epoch: 75
train loss: 5.0370660597638624e-05
auc: 0.4773344945119296
epoch: 76
train loss: 4.472015161391237e-05
auc: 0.47756723073920027
epoch: 77
train loss: 4.511627795161086e-05
auc: 0.4793803210258412
epoch: 78
train loss: 4.0425414637092605e-05
auc: 0.4796168110632292
epoch: 79
train loss: 3.76437943622864e-05
auc: 0.4786408204327392
epoch: 80
train loss: 4.696066105617351e-05
auc: 0.47861829757203556
epoch: 81
train loss: 5.8928089796525497e-05
auc: 0.4767376387032838
epoch: 82
train loss: 6.57303641736658e-05
auc: 0.4749095331761738
epoch: 83
train loss: 5.8458169839479064e-05
auc: 0.47531119085872153
epoch: 84
train loss: 3.742486578682902e-05
auc: 0.4758142014144356
epoch: 85
train loss: 3.368534738200097e-05
auc: 0.4766362858301175
epoch: 86
train loss: 3.5663593656675495e-05
auc: 0.4769328368293818
epoch: 87
train loss: 3.200850053234581e-05
auc: 0.4761858286160453
epoch: 88
train loss: 2.8165607182540692e-05
auc: 0.47802894938362434
epoch: 89
train loss: 2.9101239536315518e-05
auc: 0.4784944218381657
epoch: 90
train loss: 3.190272407836942e-05
auc: 0.47867835853391194
epoch: 91
train loss: 3.5928902884054765e-05
auc: 0.47930899863361315
epoch: 92
train loss: 2.70878275640585e-05
auc: 0.48062658598477453
epoch: 93
train loss: 2.6231759002466685e-05
auc: 0.48110707367978495
epoch: 94
train loss: 2.8291499710963114e-05
auc: 0.4807392002882926
epoch: 95
train loss: 2.494133729862955e-05
auc: 0.4821581405126203
epoch: 96
train loss: 2.2494001221265085e-05
auc: 0.4822144476643794
epoch: 97
train loss: 2.9433512820063718e-05
auc: 0.48281130347302514
epoch: 98
train loss: 3.128169649913282e-05
auc: 0.48321296115557294
epoch: 99
train loss: 2.4183391011665034e-05
auc: 0.48438790372227813
