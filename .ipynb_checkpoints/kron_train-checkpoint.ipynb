{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Parameter\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math # to check nan\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYP={\n",
    "    'node_num':128,\n",
    "    'miss_percent':0.1,\n",
    "    'seed':2052,\n",
    "    'batch_size':1024,\n",
    "    'lr_net':0.001,\n",
    "    'lr_dyn':0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_num = int(HYP['node_num']*HYP['miss_percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1cd91b4cdc8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(HYP['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dynamics learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here is a dynamics learner, and ites optimizer\n",
    "class IO_B(nn.Module):\n",
    "    \"\"\"docstring for IO_B\"\"\"\n",
    "    def __init__(self,dim,hid):\n",
    "        super(IO_B, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.hid = hid\n",
    "        self.n2e = nn.Linear(2*dim,hid)\n",
    "        self.e2e = nn.Linear(hid,hid)\n",
    "        self.e2n = nn.Linear(hid,hid)\n",
    "        self.n2n = nn.Linear(hid,hid)\n",
    "        self.output = nn.Linear(dim+hid,dim)\n",
    "    def forward(self, x, adj_col, i):\n",
    "        # x : features of all nodes at time t,[b*n*d]\n",
    "        # adj_col : i th column of adj mat,[n]\n",
    "        # i : just i\n",
    "        starter = x # [batch,node,dim]\n",
    "        ender = x[:,i,:] # [batch,dim]\n",
    "        ender = ender.unsqueeze(1) #[batch,1,dim]\n",
    "\n",
    "        ender = ender.expand(starter.size(0),starter.size(1),starter.size(2)) #[batch,node,dim]\n",
    "        x = torch.cat((starter,ender),2) #[batch,node,2dim]\n",
    "        x = F.relu(self.n2e(x))#[batch,node,hid]\n",
    "\n",
    "        x = F.relu(self.e2e(x))#[batch,node,hid]\n",
    "        adj_col = adj_col.unsqueeze(1)#[node,1]\n",
    "        adj_col = adj_col.unsqueeze(0).repeat(x.shape[0],1,x.shape[2]) #[batch,node,hid]\n",
    "        \n",
    "        x = x * adj_col#[batch,node,hid]\n",
    "\n",
    "        x = torch.sum(x,1)#[batch,hid]\n",
    "        x = F.relu(self.e2n(x))#[batch,hid]\n",
    "        x = F.relu(self.n2n(x))#[batch,hid]\n",
    "\n",
    "        x = torch.cat((starter[:,i,:],x),dim=-1)#[batch,hid+dim]\n",
    "        x = self.output(x)#[batch,dim]\n",
    "\n",
    "        # skip connection\n",
    "        # x = starter[:,i,:]+x # dont want in CML\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn = IO_B(1,16)\n",
    "op_dyn = optim.Adam(dyn.parameters(), lr=HYP['lr_dyn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kron network generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kronecker product for 2 matrix\n",
    "def kronecker(A,B):\n",
    "    return torch.einsum(\"ab,cd->acbd\", A, B).view(A.size(0)*B.size(0),  A.size(1)*B.size(1))\n",
    "\n",
    "## network generator, and ites optimizer\n",
    "class Gumbel_union_kron(nn.Module):\n",
    "    def __init__(self,sz,k):\n",
    "        super(Gumbel_union_kron,self).__init__()\n",
    "        self.p = Parameter(torch.Tensor(sz,sz).uniform_(0,0.5))\n",
    "#         self.p = Parameter(torch.tensor([[0.92,0.4],[0.5,0.6]]))\n",
    "        self.k = k\n",
    "    \n",
    "    # generate adj from original kernel\n",
    "    def generate_adj(self):\n",
    "        p0 = torch.relu(self.p-0.001)+0.001 - torch.relu(self.p-0.999)\n",
    "        adj = torch.relu(self.p-0.001)+0.001 - torch.relu(self.p-0.999)\n",
    "        for i in range(self.k-1):\n",
    "            adj = kronecker(adj,p0)\n",
    "        return adj\n",
    "    \n",
    "    def sample_all(self):\n",
    "        p1 = self.generate_adj() # prob to get 1\n",
    "        p0 = 1-p1 # prob to get 0\n",
    "        logits = torch.cat([p0.unsqueeze(2),p1.unsqueeze(2)],dim=2)#[node,node,2]\n",
    "        # log it to suit for gumbel softmax\n",
    "        logits = torch.log(logits)#[node,node,2]\n",
    "        # gumbel softmax\n",
    "        sampled_adj = torch.nn.functional.gumbel_softmax(logits,hard=False,tau=1)[:,:,1]\n",
    "        return sampled_adj\n",
    "    # generate p0 to init former gumbel generator\n",
    "    def generate_p0_for_init(self):\n",
    "        p1 = self.generate_adj() # prob to get 1\n",
    "        p0 = 1-p1 # prob to get 0\n",
    "        logits = torch.cat([p0.unsqueeze(2),p1.unsqueeze(2)],dim=2)#[node,node,2]\n",
    "        # log it to suit for gumbel softmax\n",
    "        logits = torch.log(logits)#[node,node,2]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Gumbel_union_kron(2,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = g.generate_adj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0018, 0.0016, 0.0016, 0.0015, 0.0018, 0.0016, 0.0016, 0.0015, 0.0016,\n",
       "        0.0015, 0.0015, 0.0013], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj[0,-del_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Gumbel Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal network generator\n",
    "class Gumbel_Generator(nn.Module):\n",
    "    def __init__(self,sz):\n",
    "        super(Gumbel_Generator,self).__init__()\n",
    "        self.p = Parameter(torch.randn(sz,sz,2))\n",
    "    def generate_adj(self):\n",
    "        p0 = torch.nn.functional.softmax(self.p,dim=2)[:,:,1]\n",
    "        symp0 = torch.triu(p0,diagonal=0)+torch.triu(p0,diagonal=1).transpose(0,1) # make it symmetric\n",
    "        return symp0\n",
    "    def sample_all(self):\n",
    "        sampled_adj = torch.nn.functional.gumbel_softmax(self.p,hard=False,tau=1)[:,:,1]\n",
    "        sym_adj = torch.triu(sampled_adj,diagonal=0)+torch.triu(sampled_adj,diagonal=1).transpose(0,1)# make it symmetric\n",
    "        return sym_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Gumbel_union_kron(2,7)\n",
    "# generator = Gumbel_Generator(128)\n",
    "op_net = optim.Adam(generator.parameters(), lr=HYP['lr_net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.generate_adj().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cml_ggn(data_path,batch_size = 128,node=10,seed=2050):\n",
    "\n",
    "    with open(data_path, 'rb') as f:\n",
    "        object_matrix, train_data, val_data, test_data = pickle.load(f) # (samples, nodes, timesteps, 1)\n",
    "    \n",
    "    print('\\nMatrix dimension: %s \\nTrain data size: %s \\nVal data size: %s \\nTest data size: %s'\n",
    "          % (object_matrix.shape, train_data.shape, val_data.shape, test_data.shape))    \n",
    "\n",
    "    train_loader = DataLoader(train_data[:], batch_size=batch_size, shuffle=False)#\n",
    "    val_loader = DataLoader(val_data[:], batch_size=batch_size, shuffle=False) # 记得改回来\n",
    "    test_loader = DataLoader(test_data[:], batch_size=batch_size, shuffle=False) # 记得改回来\n",
    "    return train_loader,val_loader,test_loader,object_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix dimension: torch.Size([128, 128]) \n",
      "Train data size: torch.Size([10000, 128, 2, 1]) \n",
      "Val data size: torch.Size([2000, 128, 2, 1]) \n",
      "Test data size: torch.Size([2000, 128, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_path = './data/2000cmlkron-ws128-10000-00.pickle'\n",
    "# data_path = './data/2000cmlkron-10-100-10000-00.pickle'\n",
    "\n",
    "# a = torch.load(data_path,map_location=torch.device('cpu'))\n",
    "train_loader, val_loader, test_loader, object_matrix = load_cml_ggn(data_path,batch_size=HYP['batch_size'],node=HYP['node_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_adj = object_matrix[:-del_num,:-del_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_edges = object_matrix[-del_num:,-del_num:].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unknown x generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate initial state for unobserved nodes\n",
    "class Unknown_X_Generator(nn.Module):\n",
    "    def __init__(self,batch_num,batch_sz,unobserved_node):\n",
    "        super(Unknown_X_Generator,self).__init__()\n",
    "        self.para = Parameter(torch.Tensor(batch_num,batch_sz,unobserved_node).uniform_(0,1))\n",
    "    \n",
    "    # get x\n",
    "    def get_x(self,batch_idx):\n",
    "        return self.para[batch_idx,:,:].unsqueeze(2) #[batchsz,unobserved_node,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uxg = Unknown_X_Generator(len(train_loader),HYP['batch_size'],del_num)\n",
    "op_uxg = optim.Adam(train_uxg.parameters(), lr=HYP['lr_net'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train by observed part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train by observed structure\n",
    "def train_stru():\n",
    "    op_net.zero_grad()\n",
    "#     print('before op')\n",
    "#     print(generator.p)\n",
    "    hypo_adj = generator.generate_adj()\n",
    "    o_part = hypo_adj[:-del_num,:-del_num]\n",
    "\n",
    "    loss = loss_f(o_part,observed_adj)\n",
    "#     print('loss')\n",
    "#     print(loss)\n",
    "    loss.backward()\n",
    "#     print('grad')\n",
    "#     print(generator.p.grad)\n",
    "    op_net.step()\n",
    "    \n",
    "#     print('after op')\n",
    "#     print(generator.p)\n",
    "#     d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get auc of unknown part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_unknown(p0,object_matrix,del_num):\n",
    "    yscore = []\n",
    "    y = []\n",
    "    for i in range(p0.shape[0]):\n",
    "        if i < p0.shape[0]-del_num:\n",
    "            yscore.extend(p0[i,-del_num:])\n",
    "            y.extend(object_matrix[i,-del_num:])\n",
    "        else:\n",
    "            yscore.extend(p0[i])\n",
    "            y.extend(object_matrix[i])\n",
    "    yscore = np.array(yscore)\n",
    "    y_true = np.array(y)\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, yscore,drop_intermediate=False)\n",
    "    area = metrics.auc(fpr, tpr)\n",
    "    return area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train by structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:10<00:00, 49.15it/s]\n"
     ]
    }
   ],
   "source": [
    "areas = []\n",
    "for i in tqdm(range(500)):\n",
    "    train_stru()\n",
    "#     print(generator.p)\n",
    "    p0 = generator.generate_adj().detach().numpy()\n",
    "    area = auc_unknown(p0,object_matrix,del_num)\n",
    "    areas.append(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(areas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.9274, 0.5443],\n",
       "        [0.5449, 0.6819]], requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal network generator\n",
    "class Gumbel_Generator(nn.Module):\n",
    "    def __init__(self,sz,init_p0):\n",
    "        super(Gumbel_Generator,self).__init__()\n",
    "#         self.p = Parameter(torch.randn(sz,sz,2))\n",
    "        self.p = Parameter(init_p0)\n",
    "    def generate_adj(self):\n",
    "        p0 = torch.nn.functional.softmax(self.p,dim=2)[:,:,1]\n",
    "        symp0 = torch.triu(p0,diagonal=0)+torch.triu(p0,diagonal=1).transpose(0,1) # make it symmetric\n",
    "        return symp0\n",
    "    def sample_all(self):\n",
    "        sampled_adj = torch.nn.functional.gumbel_softmax(self.p,hard=False,tau=1)[:,:,1]\n",
    "        sym_adj = torch.triu(sampled_adj,diagonal=0)+torch.triu(sampled_adj,diagonal=1).transpose(0,1)# make it symmetric\n",
    "        return sym_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_p0 = generator.generate_p0_for_init().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = Gumbel_Generator(2,init_p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dyn_gen():\n",
    "    losses = []\n",
    "    for b_idx,data in enumerate(train_loader):\n",
    "        # data:[batch,node,2,1]\n",
    "        x = data[:,:-del_num,0,:] # [batchsz,observed_node,1]\n",
    "        y = data[:,:-del_num,1,:] # same size\n",
    "        \n",
    "        # pred state for each node which can be observed\n",
    "        for j in range(HYP['node_num']-del_num):\n",
    "            print(generator.p[10,0,:])\n",
    "            op_net.zero_grad()\n",
    "            op_uxg.zero_grad()\n",
    "            op_dyn.zero_grad()\n",
    "            \n",
    "            \n",
    "            thisbatchsz = x.shape[0]\n",
    "            x_un_paed = train_uxg.get_x(b_idx)[:thisbatchsz] #[batchsz,unobserved_node,1]\n",
    "            x_hypo = torch.cat([x,x_un_paed],dim=1) #[batchsz,node,1]\n",
    "            \n",
    "            hypo_adj = generator.sample_all()\n",
    "            \n",
    "            # replace the observed part\n",
    "            t0 = torch.ones(hypo_adj.shape)\n",
    "            t0[:-del_num,:-del_num] = 0\n",
    "            t1 = torch.zeros(hypo_adj.shape)\n",
    "            t1[:-del_num,:-del_num] = observed_adj\n",
    "            hypo_adj = hypo_adj*t0+t1\n",
    "            \n",
    "            adj_col = hypo_adj[:,j]\n",
    "            \n",
    "            yhat = dyn(x_hypo,adj_col,j)\n",
    "            loss = loss_f(yhat,y[:,j,:])\n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            print(generator.p.grad[10,0,:])\n",
    "            \n",
    "            \n",
    "            op_net.step()\n",
    "            op_dyn.step()\n",
    "            op_uxg.step()\n",
    "            print(generator.p[10,0,:])\n",
    "            d()\n",
    "            losses.append(loss.item())\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = []\n",
    "losses = []\n",
    "for i in tqdm(range(10)):\n",
    "    loss = train_dyn_gen()\n",
    "    losses.append(loss)\n",
    "    # check auc\n",
    "    p0 = generator.generate_adj().detach().numpy()\n",
    "    area = auc_unknown(p0,object_matrix,del_num)\n",
    "    areas.append(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(areas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
